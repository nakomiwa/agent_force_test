import yaml
import json
import mlflow
from openai import OpenAI
from typing import Dict, Any
import datetime
from databricks.sdk.runtime import dbutils
import logging
import os

class BacePrompt:
    def __init__(self, experiment_base_path: str = "/Workspace/b_poc/b_0048/experiments"):
        self.dbutils = dbutils
        self.llm_client = None
        self._setup_llm_client()
        self.class_name = self.__class__.__name__
        
        # å®Ÿé¨“ã®ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹ã‚’è¨­å®š
        self.experiment_base_path = experiment_base_path
        self.experiment_path = f"{experiment_base_path}/{self.class_name}"
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã®è¨­å®š
        self.project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        self.config_dir = os.path.join(self.project_root, "config")
        
        # MLflowã®ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’èª¿æ•´
        logging.getLogger("mlflow").setLevel(logging.ERROR)
        
    def _setup_llm_client(self):
        scope = "my-secrets"
        key = "openai-api-key"
        api_key = self.dbutils.secrets.get(scope=scope, key=key)
        self.llm_client = OpenAI(api_key=api_key)
    
    def load_yaml(self, filename: str = "prompt.yaml") -> Dict[str, Any]:
        """
        YAMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
        Args:
            filename: config/ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: prompt.yamlï¼‰
        """
        yaml_path = os.path.join(self.config_dir, filename)
        
        try:
            with open(yaml_path, 'r', encoding='utf-8') as file:
                data = yaml.safe_load(file)
                return data.get(self.class_name, {}) if data else {}
        except FileNotFoundError:
            print(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {yaml_path}")
            return {}
        except Exception as e:
            print(f"âŒ YAMLãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def save_yaml(self, content: Dict[str, Any], filename: str = "answer.yaml"):
        """
        YAMLãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹
        Args:
            content: ä¿å­˜ã™ã‚‹å†…å®¹
            filename: config/ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: answer.yamlï¼‰
        """
        yaml_path = os.path.join(self.config_dir, filename)
        
        try:
            # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            try:
                with open(yaml_path, 'r', encoding='utf-8') as file:
                    data = yaml.safe_load(file) or {}
            except FileNotFoundError:
                data = {}
            
            # ã‚¯ãƒ©ã‚¹åã‚’ã‚­ãƒ¼ã¨ã—ã¦å†…å®¹ã‚’æ›´æ–°
            data[self.class_name] = content
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            os.makedirs(self.config_dir, exist_ok=True)  # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒãªã„å ´åˆã¯ä½œæˆ
            with open(yaml_path, 'w', encoding='utf-8') as file:
                yaml.safe_dump(data, file, allow_unicode=True, default_flow_style=False)
                
            print(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å®Œäº†: {yaml_path}")
            
        except Exception as e:
            print(f"âŒ YAMLãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _setup_mlflow_experiment(self):
        """MLflowå®Ÿé¨“ã®è¨­å®šã‚’è¡Œã†"""
        try:
            # å®Ÿé¨“ãŒæ—¢ã«å­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            experiment = mlflow.get_experiment_by_name(self.experiment_path)
            
            if experiment is None:
                # å®Ÿé¨“ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
                print(f"ğŸ”„ MLflowå®Ÿé¨“ã‚’ä½œæˆä¸­: {self.experiment_path}")
                experiment_id = mlflow.create_experiment(self.experiment_path)
                mlflow.set_experiment(experiment_id=experiment_id)
                print(f"âœ… MLflowå®Ÿé¨“ã‚’ä½œæˆã—ã¾ã—ãŸ: {self.experiment_path}")
            else:
                # å®Ÿé¨“ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯è¨­å®š
                mlflow.set_experiment(experiment_id=experiment.experiment_id)
                print(f"âœ… æ—¢å­˜ã®MLflowå®Ÿé¨“ã‚’ä½¿ç”¨: {self.experiment_path}")
                
        except Exception as e:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å®Ÿé¨“åã§ç›´æ¥è¨­å®šã‚’è©¦è¡Œ
            print(f"âš ï¸ å®Ÿé¨“è¨­å®šä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            try:
                print(f"ğŸ”„ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ–¹å¼ã§å®Ÿé¨“ã‚’è¨­å®šä¸­: {self.experiment_path}")
                mlflow.set_experiment(self.experiment_path)
                print(f"âœ… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®šå®Œäº†: {self.experiment_path}")
            except Exception as fallback_error:
                print(f"âŒ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®šã‚‚å¤±æ•—ã—ã¾ã—ãŸ: {fallback_error}")
                # æœ€å¾Œã®æ‰‹æ®µã¨ã—ã¦ä¸€æ™‚çš„ãªå®Ÿé¨“åã‚’ä½¿ç”¨
                temp_experiment = f"/tmp/{self.class_name}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}"
                print(f"ğŸ”„ ä¸€æ™‚çš„ãªå®Ÿé¨“ã‚’ä½œæˆ: {temp_experiment}")
                mlflow.set_experiment(temp_experiment)
    
    def generate(self):
        print(f"ğŸ”„ {self.class_name}: å›ç­”ç”Ÿæˆä¸­...")
        
        prompt_data = self.load_yaml("prompt.yaml")
        prompt = prompt_data.get('prompt', '')
        
        if not prompt:
            print(f"âš ï¸ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚config/prompt.yamlã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return ""
        
        response = self.llm_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.0
        )
        
        answer = response.choices[0].message.content
        
        self.save_yaml({
            "answer": answer, 
            "generated_at": datetime.datetime.now().isoformat(),
            "prompt_preview": prompt[:100] + "..." if len(prompt) > 100 else prompt
        }, "answer.yaml")
        
        return answer
    
    def evaluate(self):
        print(f"ğŸ”„ {self.class_name}: è©•ä¾¡å®Ÿè¡Œä¸­...")
        
        # generateãƒ¡ã‚½ãƒƒãƒ‰ã§ç”Ÿæˆã—ãŸå›ç­”ã‚’ãƒ­ãƒ¼ãƒ‰
        answer_data = self.load_yaml("answer.yaml")
        answer = answer_data.get('answer', '')
        
        if not answer:
            print(f"âš ï¸ è©•ä¾¡å¯¾è±¡ã®å›ç­”ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å…ˆã«generate()ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            return {"error": "å›ç­”ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}
        
        # è©•ä¾¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰
        prompt_data = self.load_yaml("prompt.yaml")
        eval_prompt_template = prompt_data.get('eval_prompt', '')
        
        if not eval_prompt_template:
            print(f"âš ï¸ è©•ä¾¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚config/prompt.yamlã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return {"error": "è©•ä¾¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}
        
        eval_prompt = eval_prompt_template.format(answer=answer)
        
        # LLMã«è©•ä¾¡ã•ã›ã‚‹
        response = self.llm_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": eval_prompt}],
            temperature=0.0
        )
        
        evaluation_result = response.choices[0].message.content
        
        try:
            evaluation_data = json.loads(evaluation_result)
        except json.JSONDecodeError:
            print(f"âš ï¸ è©•ä¾¡çµæœã®JSONè§£æã«å¤±æ•—ã—ã¾ã—ãŸ")
            evaluation_data = {"error": "è©•ä¾¡çµæœã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ", "raw_result": evaluation_result}
        
        # è©•ä¾¡çµæœã‚’ä¿å­˜
        self.save_yaml({
            "evaluation": evaluation_data,
            "evaluated_at": datetime.datetime.now().isoformat(),
            "eval_prompt_preview": eval_prompt[:100] + "..." if len(eval_prompt) > 100 else eval_prompt
        }, "evaluation.yaml")
        
        # MLFlowã«è¨˜éŒ²
        self._log_to_mlflow(answer, evaluation_data, prompt_data)
        
        return evaluation_data
    
    def _log_to_mlflow(self, answer: str, evaluation_data: Dict[str, Any], prompt_data: Dict[str, Any]):
        # å®Ÿé¨“è¨­å®š
        self._setup_mlflow_experiment()
        
        # run_nameã‚’æŒ‡å®šã—ã¦MLflowå®Ÿè¡Œé–‹å§‹
        run_name = f"{self.class_name}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        print(f"ğŸš€ MLflowå®Ÿè¡Œé–‹å§‹: {run_name}")
        
        with mlflow.start_run(run_name=run_name):
            # ============================================================
            # 1. ã‚¯ãƒ©ã‚¹ãƒ»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ã‚°
            # ============================================================
            mlflow.log_param("ã‚¯ãƒ©ã‚¹å", self.class_name)
            mlflow.log_param("å®Ÿè¡Œæ—¥æ™‚", datetime.datetime.now().isoformat())
            mlflow.log_param("ãƒ¢ãƒ‡ãƒ«å", "gpt-4o-mini")
            mlflow.log_param("Temperature", 0.0)
            mlflow.log_param("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ", self.project_root)
            mlflow.log_param("å®Ÿé¨“ãƒ‘ã‚¹", self.experiment_path)
            
            # ============================================================
            # 2. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ­ã‚°
            # ============================================================
            if 'prompt' in prompt_data:
                mlflow.log_text(prompt_data['prompt'], f"{self.class_name}_ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ.txt")
            if 'eval_prompt' in prompt_data:
                mlflow.log_text(prompt_data['eval_prompt'], f"{self.class_name}_è©•ä¾¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ.txt")
            
            # ============================================================
            # 3. ç”Ÿæˆã•ã‚ŒãŸå›ç­”ã‚’ãƒ­ã‚°
            # ============================================================
            mlflow.log_text(answer, f"{self.class_name}_å›ç­”.txt")
            mlflow.log_param("å›ç­”æ–‡å­—æ•°", len(answer))
            
            # ============================================================
            # 4. è©•ä¾¡çµæœã‚’ãƒ­ã‚°ï¼ˆè¦ªã‚¯ãƒ©ã‚¹ã§ã¯ã‚³ã‚¢ãªè©•ä¾¡ã®ã¿ï¼‰
            # ============================================================
            if isinstance(evaluation_data, dict):
                if 'ç°¡æ½”ã•' in evaluation_data:
                    mlflow.log_metric("ç°¡æ½”ã•", evaluation_data['ç°¡æ½”ã•'])
                if 'ä¸€è²«æ€§' in evaluation_data:
                    mlflow.log_metric("ä¸€è²«æ€§", evaluation_data['ä¸€è²«æ€§'])
                
                # è©•ä¾¡ç†ç”±ãŒã‚ã‚Œã°ãƒ­ã‚°
                if 'è©•ä¾¡ç†ç”±' in evaluation_data:
                    mlflow.log_text(str(evaluation_data['è©•ä¾¡ç†ç”±']), f"{self.class_name}_è©•ä¾¡ç†ç”±.txt")
            
            print(f"âœ… MLflowå®Ÿè¡Œå®Œäº†: {run_name}")
    
    def run(self):
        print(f"ğŸš€ {self.class_name} å®Ÿè¡Œé–‹å§‹...")
        print(f"ğŸ“ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ: {self.project_root}")
        print(f"ğŸ“ Configãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.config_dir}")
        print(f"ğŸ“Š MLflowå®Ÿé¨“ãƒ‘ã‚¹: {self.experiment_path}")
        
        answer = self.generate()
        if not answer:
            return {"error": "å›ç­”ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ"}
        
        print(f"âœ… å›ç­”ç”Ÿæˆå®Œäº† (æ–‡å­—æ•°: {len(answer)})")
        
        evaluation = self.evaluate()
        print(f"âœ… è©•ä¾¡å®Œäº†")
        
        return {"answer": answer, "evaluation": evaluation}