{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc5cbfba-2c28-473f-97ed-2e0153401d92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install dspy-ai openai mlflow pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85ce36cd-d229-43c8-9cb2-d410bd53f878",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bbbec1b-c330-4da2-849c-47d1e0e1abc0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ã‚»ãƒ«2: ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "from typing import List, Dict\n",
    "from openai import OpenAI\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "client = OpenAI()\n",
    "print(\"âœ“ ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad2748ad-c782-4e5e-be21-49e4dfb106ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ã‚»ãƒ«3: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆï¼ˆä¿®æ­£ç‰ˆï¼‰\n",
    "# ============================================================\n",
    "\n",
    "# é¡§å®¢ã‚µãƒãƒªãƒ¼ç”Ÿæˆã®ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹\n",
    "test_customers = [\n",
    "    {\n",
    "        \"customer_id\": \"C001\",  # idã‹ã‚‰customer_idã«å¤‰æ›´\n",
    "        \"name\": \"å±±ç”°å¤ªéƒ\",\n",
    "        \"age\": 35,\n",
    "        \"occupation\": \"ä¼šç¤¾å“¡\",\n",
    "        \"purchase_history\": \"éå»6ãƒ¶æœˆã§é›»åŒ–è£½å“ã‚’3å›è³¼å…¥\",\n",
    "        \"inquiries\": \"é…é€ã«é–¢ã™ã‚‹å•ã„åˆã‚ã›2ä»¶ã€è£½å“ã®ä½¿ã„æ–¹1ä»¶\",\n",
    "        \"notes\": \"ãƒ¡ãƒ¼ãƒ«ãƒã‚¬ã‚¸ãƒ³è³¼èª­ä¸­ã€æ¬¡å›è³¼å…¥æ™‚10%å‰²å¼•ã‚¯ãƒ¼ãƒãƒ³ä¿æœ‰\"\n",
    "    },\n",
    "    {\n",
    "        \"customer_id\": \"C002\",\n",
    "        \"name\": \"ä½è—¤èŠ±å­\",\n",
    "        \"age\": 28,\n",
    "        \"occupation\": \"ãƒ•ãƒªãƒ¼ãƒ©ãƒ³ã‚¹ãƒ‡ã‚¶ã‚¤ãƒŠãƒ¼\",\n",
    "        \"purchase_history\": \"åˆå›è³¼å…¥ã€ãƒãƒ¼ãƒˆPC 1å°\",\n",
    "        \"inquiries\": \"è£½å“ä»•æ§˜ã®è©³ç´°ç¢ºèªã€ç´æœŸç¢ºèª\",\n",
    "        \"notes\": \"ä¼æ¥­å‘ã‘ã‚¢ã‚«ã‚¦ãƒ³ãƒˆæ¤œè¨ä¸­ã€è¦‹ç©ä¾é ¼ã‚ã‚Š\"\n",
    "    },\n",
    "    {\n",
    "        \"customer_id\": \"C003\",\n",
    "        \"name\": \"éˆ´æœ¨ä¸€éƒ\",\n",
    "        \"age\": 52,\n",
    "        \"occupation\": \"è‡ªå–¶æ¥­\",\n",
    "        \"purchase_history\": \"æœˆ1å›ãƒšãƒ¼ã‚¹ã§äº‹å‹™ç”¨å“ã‚’è³¼å…¥ã€ç´¯è¨ˆ15å›\",\n",
    "        \"inquiries\": \"è«‹æ±‚æ›¸ç™ºè¡Œä¾é ¼ãŒå¤šã„\",\n",
    "        \"notes\": \"æ³•äººå¥‘ç´„å¸Œæœ›ã€å¤§é‡ç™ºæ³¨ã®å¯èƒ½æ€§ã‚ã‚Š\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"âœ“ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(test_customers)}ä»¶\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffb37b22-8988-4dae-91f6-7302b81ebaf6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ã‚»ãƒ«4: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒ¼ã‚¸ãƒ§ãƒ³å®šç¾©\n",
    "# ============================================================\n",
    "\n",
    "# è©•ä¾¡å¯¾è±¡ã®è¤‡æ•°ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒ¼ã‚¸ãƒ§ãƒ³\n",
    "prompt_versions = {\n",
    "    \"v1_basic\": \"\"\"\n",
    "ä»¥ä¸‹ã®é¡§å®¢æƒ…å ±ã‚’200æ–‡å­—ä»¥å†…ã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "é¡§å®¢ID: {customer_id}\n",
    "åå‰: {name}\n",
    "å¹´é½¢: {age}\n",
    "è·æ¥­: {occupation}\n",
    "è³¼å…¥å±¥æ­´: {purchase_history}\n",
    "å•ã„åˆã‚ã›å±¥æ­´: {inquiries}\n",
    "å‚™è€ƒ: {notes}\n",
    "\"\"\",\n",
    "    \n",
    "    \"v2_structured\": \"\"\"\n",
    "ä»¥ä¸‹ã®é¡§å®¢æƒ…å ±ã‚’ã€é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’æŠ¼ã•ãˆã¦ç°¡æ½”ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "ã€åŸºæœ¬æƒ…å ±ã€‘\n",
    "- é¡§å®¢ID: {customer_id}\n",
    "- åå‰: {name}ï¼ˆ{age}æ­³ã€{occupation}ï¼‰\n",
    "\n",
    "ã€å–å¼•çŠ¶æ³ã€‘\n",
    "- è³¼å…¥: {purchase_history}\n",
    "- å•ã„åˆã‚ã›: {inquiries}\n",
    "\n",
    "ã€ç‰¹è¨˜äº‹é …ã€‘\n",
    "{notes}\n",
    "\n",
    "ã€è¦ç´„è¦ä»¶ã€‘\n",
    "- 200æ–‡å­—ä»¥å†…\n",
    "- å–¶æ¥­æ‹…å½“è€…ãŒæ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’åˆ¤æ–­ã§ãã‚‹å†…å®¹\n",
    "- æ•°å€¤ãƒ»å…·ä½“çš„äº‹å®Ÿã‚’å„ªå…ˆ\n",
    "\"\"\",\n",
    "    \n",
    "    \"v3_actionable\": \"\"\"\n",
    "å–¶æ¥­æ‹…å½“è€…å‘ã‘ã«ã€ä»¥ä¸‹ã®é¡§å®¢æƒ…å ±ã‹ã‚‰æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³åˆ¤æ–­ã«å¿…è¦ãªè¦ç‚¹ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "é¡§å®¢: {name}ï¼ˆID: {customer_id}ã€{age}æ­³ã€{occupation}ï¼‰\n",
    "è³¼å…¥å±¥æ­´: {purchase_history}\n",
    "å•ã„åˆã‚ã›: {inquiries}\n",
    "å‚™è€ƒ: {notes}\n",
    "\n",
    "ä»¥ä¸‹ã®è¦³ç‚¹ã§200æ–‡å­—ä»¥å†…ã§è¦ç´„:\n",
    "1. é¡§å®¢ã®è³¼è²·ãƒ‘ã‚¿ãƒ¼ãƒ³\n",
    "2. ç¾åœ¨ã®ãƒ‹ãƒ¼ã‚ºã‚„èª²é¡Œ\n",
    "3. æ¬¡ã«ææ¡ˆã™ã¹ãå†…å®¹\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "print(f\"âœ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒ¼ã‚¸ãƒ§ãƒ³: {len(prompt_versions)}å€‹\")\n",
    "for version in prompt_versions.keys():\n",
    "    print(f\"  - {version}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd8c5da2-2eea-4f55-b26d-627bccddda26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ã‚»ãƒ«5: æ¨è«–å®Ÿè¡Œé–¢æ•°\n",
    "# ============================================================\n",
    "\n",
    "def generate_summary(customer: Dict, prompt_template: str, model: str = \"gpt-4o-mini\") -> str:\n",
    "    \"\"\"\n",
    "    ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«é¡§å®¢ãƒ‡ãƒ¼ã‚¿ã‚’åŸ‹ã‚è¾¼ã‚“ã§è¦ç´„ç”Ÿæˆ\n",
    "    \"\"\"\n",
    "    prompt = prompt_template.format(**customer)\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"ã‚ãªãŸã¯å„ªç§€ãªã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆæ‹…å½“è€…ã§ã™ã€‚\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "        max_tokens=300\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "print(\"âœ“ æ¨è«–é–¢æ•°å®šç¾©å®Œäº†\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b7e2443-bc5d-46d5-a02e-c27fdfb968f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ã‚»ãƒ«6: è©•ä¾¡é–¢æ•°ï¼ˆLLM-as-a-Judgeï¼‰\n",
    "# ============================================================\n",
    "\n",
    "def evaluate_summary(customer: Dict, summary: str) -> Dict:\n",
    "    \"\"\"\n",
    "    ç”Ÿæˆã•ã‚ŒãŸè¦ç´„ã‚’è©•ä¾¡\n",
    "    \n",
    "    Returns:\n",
    "        {\n",
    "            \"score\": float (0.0-1.0),\n",
    "            \"reasoning\": str,\n",
    "            \"metrics\": {\n",
    "                \"conciseness\": float,\n",
    "                \"clarity\": float,\n",
    "                \"actionability\": float\n",
    "            }\n",
    "        }\n",
    "    \"\"\"\n",
    "    \n",
    "    evaluation_prompt = f\"\"\"\n",
    "ä»¥ä¸‹ã®é¡§å®¢è¦ç´„ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "ã€å…ƒãƒ‡ãƒ¼ã‚¿ã€‘\n",
    "é¡§å®¢: {customer['name']} ({customer['age']}æ­³ã€{customer['occupation']})\n",
    "è³¼å…¥å±¥æ­´: {customer['purchase_history']}\n",
    "å•ã„åˆã‚ã›: {customer['inquiries']}\n",
    "å‚™è€ƒ: {customer['notes']}\n",
    "\n",
    "ã€ç”Ÿæˆã•ã‚ŒãŸè¦ç´„ã€‘\n",
    "{summary}\n",
    "\n",
    "ã€è©•ä¾¡åŸºæº–ã€‘\n",
    "1. ç°¡æ½”æ€§ (0-10): 200æ–‡å­—ä»¥å†…ã§ç„¡é§„ãŒãªã„ã‹\n",
    "2. æ˜ç­æ€§ (0-10): é‡è¦æƒ…å ±ãŒæ˜ç¢ºã«ä¼ã‚ã‚‹ã‹\n",
    "3. å®Ÿç”¨æ€§ (0-10): æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³åˆ¤æ–­ã«å½¹ç«‹ã¤ã‹\n",
    "\n",
    "ä»¥ä¸‹ã®JSONå½¢å¼ã§è©•ä¾¡ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„:\n",
    "{{\n",
    "  \"conciseness\": <0-10ã®æ•´æ•°>,\n",
    "  \"clarity\": <0-10ã®æ•´æ•°>,\n",
    "  \"actionability\": <0-10ã®æ•´æ•°>,\n",
    "  \"reasoning\": \"<è©•ä¾¡ç†ç”±>\"\n",
    "}}\n",
    "\"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"ã‚ãªãŸã¯å³æ­£ãªå“è³ªè©•ä¾¡è€…ã§ã™ã€‚\"},\n",
    "            {\"role\": \"user\", \"content\": evaluation_prompt}\n",
    "        ],\n",
    "        temperature=0.1,\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    \n",
    "    result = json.loads(response.choices[0].message.content)\n",
    "    \n",
    "    # ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆå¹³å‡ã‚’0-1ã«æ­£è¦åŒ–ï¼‰\n",
    "    total_score = (\n",
    "        result[\"conciseness\"] + \n",
    "        result[\"clarity\"] + \n",
    "        result[\"actionability\"]\n",
    "    ) / 30.0\n",
    "    \n",
    "    return {\n",
    "        \"score\": total_score,\n",
    "        \"reasoning\": result.get(\"reasoning\", \"\"),\n",
    "        \"metrics\": {\n",
    "            \"conciseness\": result[\"conciseness\"] / 10.0,\n",
    "            \"clarity\": result[\"clarity\"] / 10.0,\n",
    "            \"actionability\": result[\"actionability\"] / 10.0\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(\"âœ“ è©•ä¾¡é–¢æ•°å®šç¾©å®Œäº†\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1ef4b08-6ffc-40e7-a028-7ccfb283cdd7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ã‚»ãƒ«7: è©•ä¾¡å®Ÿé¨“å®Ÿè¡Œ\n",
    "# ============================================================\n",
    "\n",
    "# MLflowå®Ÿé¨“è¨­å®š\n",
    "mlflow.set_experiment(experiment_id=2762244084694129)\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè©•ä¾¡å®Ÿé¨“é–‹å§‹\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for version_name, prompt_template in prompt_versions.items():\n",
    "    print(f\"\\nğŸ“‹ è©•ä¾¡ä¸­: {version_name}\")\n",
    "    \n",
    "    with mlflow.start_run(run_name=version_name):\n",
    "        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ­ã‚°\n",
    "        mlflow.log_param(\"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒ¼ã‚¸ãƒ§ãƒ³\", version_name)\n",
    "        mlflow.log_text(prompt_template, \"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ.txt\")\n",
    "        \n",
    "        version_scores = []\n",
    "        \n",
    "        for customer in test_customers:\n",
    "            print(f\"  â†’ {customer['name']}\")\n",
    "            \n",
    "            # è¦ç´„ç”Ÿæˆ\n",
    "            summary = generate_summary(customer, prompt_template)\n",
    "            \n",
    "            # è©•ä¾¡å®Ÿè¡Œ\n",
    "            evaluation = evaluate_summary(customer, summary)\n",
    "            \n",
    "            # çµæœè¨˜éŒ²\n",
    "            result = {\n",
    "                \"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒ¼ã‚¸ãƒ§ãƒ³\": version_name,\n",
    "                \"é¡§å®¢ID\": customer[\"customer_id\"],\n",
    "                \"é¡§å®¢å\": customer[\"name\"],\n",
    "                \"è¦ç´„\": summary,\n",
    "                \"ç·åˆã‚¹ã‚³ã‚¢\": evaluation[\"score\"],\n",
    "                \"ç°¡æ½”æ€§\": evaluation[\"metrics\"][\"conciseness\"],\n",
    "                \"æ˜ç­æ€§\": evaluation[\"metrics\"][\"clarity\"],\n",
    "                \"å®Ÿç”¨æ€§\": evaluation[\"metrics\"][\"actionability\"],\n",
    "                \"è©•ä¾¡ç†ç”±\": evaluation[\"reasoning\"]\n",
    "            }\n",
    "            \n",
    "            results.append(result)\n",
    "            version_scores.append(evaluation[\"score\"])\n",
    "            \n",
    "            print(f\"     ã‚¹ã‚³ã‚¢: {evaluation['score']:.2%}\")\n",
    "        \n",
    "        # ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã”ã¨ã®å¹³å‡ã‚¹ã‚³ã‚¢ã‚’ãƒ­ã‚°\n",
    "        avg_score = sum(version_scores) / len(version_scores)\n",
    "        mlflow.log_metric(\"å¹³å‡ã‚¹ã‚³ã‚¢\", avg_score)\n",
    "        mlflow.log_metric(\"å¹³å‡_ç°¡æ½”æ€§\", sum(r[\"ç°¡æ½”æ€§\"] for r in results[-len(test_customers):]) / len(test_customers))\n",
    "        mlflow.log_metric(\"å¹³å‡_æ˜ç­æ€§\", sum(r[\"æ˜ç­æ€§\"] for r in results[-len(test_customers):]) / len(test_customers))\n",
    "        mlflow.log_metric(\"å¹³å‡_å®Ÿç”¨æ€§\", sum(r[\"å®Ÿç”¨æ€§\"] for r in results[-len(test_customers):]) / len(test_customers))\n",
    "        \n",
    "        print(f\"  âœ“ å¹³å‡ã‚¹ã‚³ã‚¢: {avg_score:.2%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ“ è©•ä¾¡å®Ÿé¨“å®Œäº†\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f9ea235-f2c5-4449-859d-be04d4a5fb91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "llm",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
